{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manga, Manhua, Manhwa Recommender System\n",
    "Just some practice for recommender systems. This notebook is based off [Manga, Manhwa and Manhua Dataset](https://www.kaggle.com/datasets/victorsoeiro/manga-manhwa-and-manhua-dataset) by Victor Soeiro on Kaggle. This practice is my research to finding out how to make good recommender systems and, specifically, in the style I wish to see. Simply looking for ways to reach the best recommendations, relying *more* on my own tastes, wants, and curiosities rather than others deem reputable or what is profitable. \n",
    "\n",
    "Dataset is flawed (in my opinion). Some have repeats (like part 1, part 2 or episode 0, episode 1 when the story should be treated as one entry and not several). The website which the information was scrapped off of also do not involve detailed enough tags. If you want to see most of the project, skip to step 2!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\noble\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\noble\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\noble\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\noble\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\noble\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\noble\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\noble\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\noble\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\noble\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\noble\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\noble\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\noble\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.4.6)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\noble\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (2.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\noble\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\noble\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\noble\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\noble\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\noble\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\noble\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\noble\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.5.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\noble\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\noble\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (2.1.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\noble\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\noble\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\noble\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\noble\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.14.1)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\noble\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy<2.3,>=1.23.5 in c:\\users\\noble\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scipy) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn\n",
    "!pip install scipy\n",
    "!pip install zarr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>rating</th>\n",
       "      <th>year</th>\n",
       "      <th>tags</th>\n",
       "      <th>cover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Salad Days (Tang LiuZang) - Part 2</td>\n",
       "      <td>The second season of Salad Days (Tang LiuZang).</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>['BL', 'Manhua', 'Romance', 'Shounen-ai', 'Spo...</td>\n",
       "      <td>https://cdn.anime-planet.com/manga/primary/sal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Master of Diabolism</td>\n",
       "      <td>As the grandmaster who founded the Demonic Sec...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>['Action', 'Adventure', 'BL', 'Comedy', 'Manhu...</td>\n",
       "      <td>https://cdn.anime-planet.com/manga/primary/the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JoJo's Bizarre Adventure Part 7: Steel Ball Run</td>\n",
       "      <td>Set in 1890, Steel Ball Run spotlights Gyro Ze...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>['Action', 'Adventure', 'Horror', 'Mystery', '...</td>\n",
       "      <td>https://cdn.anime-planet.com/manga/primary/joj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Sign of Affection</td>\n",
       "      <td>Yuki is a typical college student, whose world...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>['Romance', 'Shoujo', 'Slice of Life', 'Disabi...</td>\n",
       "      <td>https://cdn.anime-planet.com/manga/primary/a-s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Moriarty the Patriot</td>\n",
       "      <td>Before he was Sherlock’s rival, Moriarty fough...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>['Mystery', 'Shounen', 'Detectives', 'England'...</td>\n",
       "      <td>https://cdn.anime-planet.com/manga/primary/mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Classroom of the Elite (Light Novel)</td>\n",
       "      <td>At the prestigious Tokyo Metropolitan Advanced...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>['Comedy', 'Drama', 'Ecchi', 'Harem', 'Light N...</td>\n",
       "      <td>https://cdn.anime-planet.com/manga/primary/cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Who Made Me a Princess</td>\n",
       "      <td>The beautiful Athanasia was killed at the hand...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>['Fantasy', 'Manhwa', 'Romance', 'Slice of Lif...</td>\n",
       "      <td>https://cdn.anime-planet.com/manga/primary/who...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Demon Slayer: Kimetsu no Yaiba</td>\n",
       "      <td>The setting is Taisho era Japan. Tanjirou is a...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>['Action', 'Adventure', 'Comedy', 'Drama', 'Fa...</td>\n",
       "      <td>https://cdn.anime-planet.com/manga/primary/dem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Omniscient Reader (Novel)</td>\n",
       "      <td>One day, our MC finds himself stuck in the wor...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>['Action', 'Adventure', 'Drama', 'Fantasy', 'M...</td>\n",
       "      <td>https://cdn.anime-planet.com/manga/primary/omn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Omniscient Reader</td>\n",
       "      <td>Back then, Dokja had no idea. He had no idea h...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>['Action', 'Adventure', 'Drama', 'Fantasy', 'M...</td>\n",
       "      <td>https://cdn.anime-planet.com/manga/primary/omn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title  \\\n",
       "0               Salad Days (Tang LiuZang) - Part 2   \n",
       "1                          The Master of Diabolism   \n",
       "2  JoJo's Bizarre Adventure Part 7: Steel Ball Run   \n",
       "3                              A Sign of Affection   \n",
       "4                             Moriarty the Patriot   \n",
       "5             Classroom of the Elite (Light Novel)   \n",
       "6                           Who Made Me a Princess   \n",
       "7                   Demon Slayer: Kimetsu no Yaiba   \n",
       "8                        Omniscient Reader (Novel)   \n",
       "9                                Omniscient Reader   \n",
       "\n",
       "                                         description  rating    year  \\\n",
       "0    The second season of Salad Days (Tang LiuZang).     4.7  2021.0   \n",
       "1  As the grandmaster who founded the Demonic Sec...     4.7  2017.0   \n",
       "2  Set in 1890, Steel Ball Run spotlights Gyro Ze...     4.7  2004.0   \n",
       "3  Yuki is a typical college student, whose world...     4.7  2019.0   \n",
       "4  Before he was Sherlock’s rival, Moriarty fough...     4.7  2016.0   \n",
       "5  At the prestigious Tokyo Metropolitan Advanced...     4.7  2015.0   \n",
       "6  The beautiful Athanasia was killed at the hand...     4.7  2017.0   \n",
       "7  The setting is Taisho era Japan. Tanjirou is a...     4.7  2016.0   \n",
       "8  One day, our MC finds himself stuck in the wor...     4.7  2018.0   \n",
       "9  Back then, Dokja had no idea. He had no idea h...     4.7  2020.0   \n",
       "\n",
       "                                                tags  \\\n",
       "0  ['BL', 'Manhua', 'Romance', 'Shounen-ai', 'Spo...   \n",
       "1  ['Action', 'Adventure', 'BL', 'Comedy', 'Manhu...   \n",
       "2  ['Action', 'Adventure', 'Horror', 'Mystery', '...   \n",
       "3  ['Romance', 'Shoujo', 'Slice of Life', 'Disabi...   \n",
       "4  ['Mystery', 'Shounen', 'Detectives', 'England'...   \n",
       "5  ['Comedy', 'Drama', 'Ecchi', 'Harem', 'Light N...   \n",
       "6  ['Fantasy', 'Manhwa', 'Romance', 'Slice of Lif...   \n",
       "7  ['Action', 'Adventure', 'Comedy', 'Drama', 'Fa...   \n",
       "8  ['Action', 'Adventure', 'Drama', 'Fantasy', 'M...   \n",
       "9  ['Action', 'Adventure', 'Drama', 'Fantasy', 'M...   \n",
       "\n",
       "                                               cover  \n",
       "0  https://cdn.anime-planet.com/manga/primary/sal...  \n",
       "1  https://cdn.anime-planet.com/manga/primary/the...  \n",
       "2  https://cdn.anime-planet.com/manga/primary/joj...  \n",
       "3  https://cdn.anime-planet.com/manga/primary/a-s...  \n",
       "4  https://cdn.anime-planet.com/manga/primary/mor...  \n",
       "5  https://cdn.anime-planet.com/manga/primary/cla...  \n",
       "6  https://cdn.anime-planet.com/manga/primary/who...  \n",
       "7  https://cdn.anime-planet.com/manga/primary/dem...  \n",
       "8  https://cdn.anime-planet.com/manga/primary/omn...  \n",
       "9  https://cdn.anime-planet.com/manga/primary/omn...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove cover since we don't need the links to make recommendations.\n",
    "\n",
    "Initially, I had an issue about the possibility that description could cause confusion in the model. Let's say we use Term Frequency-Inverse Document Frequency (TF-IDF). This would catch words that could cause confusion. If recommendations were based closely on words in descriptions, someone who likes the manga Blue Period may accidentally get the recommendation Sweet Home, two entirely different stories of different styles simply because the main character in the description is a high school student.\n",
    "\n",
    "But, for now, we leave it to be included. We could find a better way to calculating the weight of description similarity in the later parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = ['cover']\n",
    "df = df.drop(columns=remove)\n",
    "df = df.drop_duplicates(subset='title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Simple Version\n",
    "Let's think of this recommender system pretty one-dimensionally. Since we don't have much statistics on how these comics were rated and, in some sense, might not be the most reliable ratings due to demographic differences and possible other factors, demographic filtering might not be the best choice for this dataset.\n",
    "\n",
    "If we try content based filtering, we might get better results. For the simple version, let's take the features we have narrow down to and do some similarity score processing. I found out there are two different ways of using NLP to understand and extract text/words to calculate for similarity: CountVectorizer and TfidfVectorizer. Let's try them both!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer Version\n",
    "For this conversion method, we must create a metadata soup for the method to take things in. While rating is very important, for the sake of this method, we will omit it. After all, if you liked a comic rated 2.1, would you want a recommendation for a comic of a similar scoring? Probably not. \n",
    "\n",
    "While year can be really important to finding underlying patterns that the tags cannot, for the sake of this section it will be omitted. This is because comparing year numerically like determining the generation gap between two comics is more valuable than comparing the string value of the year which is what these two vector methods do. We will also address this problem later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "df['tags'] = df['tags'].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list(x):\n",
    "    if isinstance(x, list):\n",
    "        names = x\n",
    "        if len(names) > 9:\n",
    "            names = names[:9]\n",
    "        return names\n",
    "    return []\n",
    "\n",
    "def clean_data(x):\n",
    "    if isinstance(x, list):\n",
    "        return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
    "    \n",
    "def create_soup(x):\n",
    "    return ' '.join(x['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>rating</th>\n",
       "      <th>year</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Salad Days (Tang LiuZang) - Part 2</td>\n",
       "      <td>The second season of Salad Days (Tang LiuZang).</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>[BL, Manhua, Romance, Shounen-ai, Sports, Webt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Master of Diabolism</td>\n",
       "      <td>As the grandmaster who founded the Demonic Sec...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>[Action, Adventure, BL, Comedy, Manhua, Myster...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JoJo's Bizarre Adventure Part 7: Steel Ball Run</td>\n",
       "      <td>Set in 1890, Steel Ball Run spotlights Gyro Ze...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>[Action, Adventure, Horror, Mystery, Seinen, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title  \\\n",
       "0               Salad Days (Tang LiuZang) - Part 2   \n",
       "1                          The Master of Diabolism   \n",
       "2  JoJo's Bizarre Adventure Part 7: Steel Ball Run   \n",
       "\n",
       "                                         description  rating    year  \\\n",
       "0    The second season of Salad Days (Tang LiuZang).     4.7  2021.0   \n",
       "1  As the grandmaster who founded the Demonic Sec...     4.7  2017.0   \n",
       "2  Set in 1890, Steel Ball Run spotlights Gyro Ze...     4.7  2004.0   \n",
       "\n",
       "                                                tags  \n",
       "0  [BL, Manhua, Romance, Shounen-ai, Sports, Webt...  \n",
       "1  [Action, Adventure, BL, Comedy, Manhua, Myster...  \n",
       "2  [Action, Adventure, Horror, Mystery, Seinen, 1...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tags'] = df['tags'].apply(get_list)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df['tags'] = df['tags'].apply(clean_data)\n",
    "df['soup'] = df.apply(create_soup, axis=1)\n",
    "count = CountVectorizer(stop_words='english') # good habit to rid possible filler words\n",
    "count_matrix = count.fit_transform(df['soup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "reduced_matrix = svd.fit_transform(count_matrix)\n",
    "\n",
    "reduced_similarity = cosine_similarity(reduced_matrix, reduced_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "indices = pd.Series(df.index, index=df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_recs(title, similarity, amt):\n",
    "    idx = indices[title] \n",
    "    similarity_scores = list(enumerate(similarity[idx]))\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    similarity_scores = similarity_scores[1:amt]\n",
    "    \n",
    "    comic_indices = [i[0] for i in similarity_scores]\n",
    "    scores = [i[1] for i in similarity_scores]\n",
    "    \n",
    "    titles = df['title'].iloc[comic_indices].reset_index(drop=True)\n",
    "    results = pd.DataFrame({'title': titles, 'similarity_score': scores})\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It's Been a While Since the Original Was Finished</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'll Marry Him!</td>\n",
       "      <td>0.992990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tricked into Becoming the Heroine's Stepmother</td>\n",
       "      <td>0.940253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miss Not-So Sidekick</td>\n",
       "      <td>0.940171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Male Lead's Little Lion Daughter</td>\n",
       "      <td>0.939137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Another Typical Fantasy Romance</td>\n",
       "      <td>0.938971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Villainesses Have More Fun</td>\n",
       "      <td>0.938711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Tyrant's Only Perfumer</td>\n",
       "      <td>0.938711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Villainess's Idol</td>\n",
       "      <td>0.938711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  similarity_score\n",
       "0  It's Been a While Since the Original Was Finished          1.000000\n",
       "1                                    I'll Marry Him!          0.992990\n",
       "2     Tricked into Becoming the Heroine's Stepmother          0.940253\n",
       "3                               Miss Not-So Sidekick          0.940171\n",
       "4               The Male Lead's Little Lion Daughter          0.939137\n",
       "5                    Another Typical Fantasy Romance          0.938971\n",
       "6                         Villainesses Have More Fun          0.938711\n",
       "7                         The Tyrant's Only Perfumer          0.938711\n",
       "8                                  Villainess's Idol          0.938711"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_simple_recs('Beware the Villainess!', reduced_similarity, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer Version\n",
    "This conversion method we will also omit the rating since we aren't looking for that possibly false way of comparing for similarity. The same thing for year happens hear since we aren't looking at using integer values quite yet. We will have to find another way to create a similarity score based off of all 3 main factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list(x):\n",
    "    if isinstance(x, list):\n",
    "        names = x\n",
    "        if len(names) > 12:\n",
    "            names = names[:12]\n",
    "        return names\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>rating</th>\n",
       "      <th>year</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Salad Days (Tang LiuZang) - Part 2</td>\n",
       "      <td>The second season of Salad Days (Tang LiuZang).</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>[bl, manhua, romance, shounen-ai, sports, webt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Master of Diabolism</td>\n",
       "      <td>As the grandmaster who founded the Demonic Sec...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>[action, adventure, bl, comedy, manhua, myster...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JoJo's Bizarre Adventure Part 7: Steel Ball Run</td>\n",
       "      <td>Set in 1890, Steel Ball Run spotlights Gyro Ze...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>[action, adventure, horror, mystery, seinen, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Sign of Affection</td>\n",
       "      <td>Yuki is a typical college student, whose world...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>[romance, shoujo, sliceoflife, disability]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Moriarty the Patriot</td>\n",
       "      <td>Before he was Sherlock’s rival, Moriarty fough...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>[mystery, shounen, detectives, england, europe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title  \\\n",
       "0               Salad Days (Tang LiuZang) - Part 2   \n",
       "1                          The Master of Diabolism   \n",
       "2  JoJo's Bizarre Adventure Part 7: Steel Ball Run   \n",
       "3                              A Sign of Affection   \n",
       "4                             Moriarty the Patriot   \n",
       "\n",
       "                                         description  rating    year  \\\n",
       "0    The second season of Salad Days (Tang LiuZang).     4.7  2021.0   \n",
       "1  As the grandmaster who founded the Demonic Sec...     4.7  2017.0   \n",
       "2  Set in 1890, Steel Ball Run spotlights Gyro Ze...     4.7  2004.0   \n",
       "3  Yuki is a typical college student, whose world...     4.7  2019.0   \n",
       "4  Before he was Sherlock’s rival, Moriarty fough...     4.7  2016.0   \n",
       "\n",
       "                                                tags  \n",
       "0  [bl, manhua, romance, shounen-ai, sports, webt...  \n",
       "1  [action, adventure, bl, comedy, manhua, myster...  \n",
       "2  [action, adventure, horror, mystery, seinen, 1...  \n",
       "3         [romance, shoujo, sliceoflife, disability]  \n",
       "4  [mystery, shounen, detectives, england, europe...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "remove = ['cover']\n",
    "df = df.drop(columns=remove)\n",
    "\n",
    "\n",
    "df['tags'] = df['tags'].apply(literal_eval)\n",
    "df['tags'] = df['tags'].apply(get_list)\n",
    "df['tags'] = df['tags'].apply(clean_data)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()\n",
    "indices = pd.Series(df.index, index=df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70945, 589)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "df['tags'] = df['tags'].apply(lambda x: ' '.join(x) if isinstance(x, list) else '')\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "df['tags'] = df['tags'].fillna('')\n",
    "\n",
    "tfidf_matrix = tfidf.fit_transform(df['tags'])\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "reduced_tfidf_matrix = svd.fit_transform(tfidf_matrix)\n",
    "\n",
    "reduced_similarity = linear_kernel(reduced_tfidf_matrix, reduced_tfidf_matrix)\n",
    "\n",
    "indices = pd.Series(df.index, index=df['title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here Comes the Silver Spoon!</td>\n",
       "      <td>0.823919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Lady Tames the Swordmaster</td>\n",
       "      <td>0.823919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tricked into Becoming the Heroine's Stepmother</td>\n",
       "      <td>0.796597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beware the Villainess!</td>\n",
       "      <td>0.792703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Evil Cinderella Needs a Villain</td>\n",
       "      <td>0.790021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I Woke Up as the Ugly Duckling</td>\n",
       "      <td>0.785855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Miss Not-So Sidekick</td>\n",
       "      <td>0.780704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>It's Been a While Since the Original Was Finished</td>\n",
       "      <td>0.779653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Becoming the Dark Hero's Daughter</td>\n",
       "      <td>0.777913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  similarity_score\n",
       "0                       Here Comes the Silver Spoon!          0.823919\n",
       "1                     The Lady Tames the Swordmaster          0.823919\n",
       "2     Tricked into Becoming the Heroine's Stepmother          0.796597\n",
       "3                             Beware the Villainess!          0.792703\n",
       "4                The Evil Cinderella Needs a Villain          0.790021\n",
       "5                     I Woke Up as the Ugly Duckling          0.785855\n",
       "6                               Miss Not-So Sidekick          0.780704\n",
       "7  It's Been a While Since the Original Was Finished          0.779653\n",
       "8                  Becoming the Dark Hero's Daughter          0.777913"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_simple_recs('Beware the Villainess!', reduced_similarity, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in the end, we get two quite different results. With the level that I am working in, there is not much more I can do. Tags may not be reliable enough and a lot goes into the math of the functions we decide to use when creating the similarity score. A way to better improve this work is to include the rest of the features, namely the description, year, and rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Individual Recommender\n",
    "Now that we kind of get the gist of the most important part of our recommender: the tags, we have the option to upgrade our calculating of scores. Because all four parts, descripion, rating, year, and tags are so different in how they are assessed and used when looking at a piece of media, we have to treat all three pieces differently.\n",
    "\n",
    "This is how I want it done:\n",
    "* tags are the most important, it defines taste but weighing too much of it can overfit the data\n",
    "* good ratings are only important if results reflect taste and poor ratings are not desired\n",
    "* year is only important for underlying patterns that appear as trends through time\n",
    "* descriptions can be the factor to differentiating core elements, not styles, between each media\n",
    "\n",
    "All that would mean, different factors will be weighed differently. In a simple equation, it can look something like this:\n",
    "$$S=(S_t×w_t)+(S_y×w_y)+(S_r×w_r)+(S_d×w_d)$$\n",
    "\n",
    "where:\n",
    "* $S, S_t, S_y, S_r, S_d$ - similarity, tag similarity, year similarity, rating similarity, decription similarity\n",
    "* $w_t, w_y, w_r, w_d$ - tag weight, year weight, rating weight, decription weight\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.1: Redefining\n",
    "Now, because we're doing the recommendation a different way, let's reload the database and process everything over again. This makes sure that we aren't using the old data that could mess anything up. Also this is easier for me to rerun the notebook from this step directly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list(x):\n",
    "    if isinstance(x, list):\n",
    "        names = x\n",
    "        if len(names) > 9:\n",
    "            names = names[:9]\n",
    "        return names\n",
    "    return []\n",
    "\n",
    "def clean_data(x):\n",
    "    if isinstance(x, list):\n",
    "        return [str.lower(i.replace(\" \", \"\")) for i in x]\n",
    "    \n",
    "def create_soup(x):\n",
    "    return ' '.join(x['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>rating</th>\n",
       "      <th>year</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Salad Days (Tang LiuZang) - Part 2</td>\n",
       "      <td>The second season of Salad Days (Tang LiuZang).</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>[bl, manhua, romance, shounen-ai, sports, webt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Master of Diabolism</td>\n",
       "      <td>As the grandmaster who founded the Demonic Sec...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>[action, adventure, bl, comedy, manhua, myster...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JoJo's Bizarre Adventure Part 7: Steel Ball Run</td>\n",
       "      <td>Set in 1890, Steel Ball Run spotlights Gyro Ze...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>[action, adventure, horror, mystery, seinen, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Sign of Affection</td>\n",
       "      <td>Yuki is a typical college student, whose world...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>[romance, shoujo, sliceoflife, disability]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Moriarty the Patriot</td>\n",
       "      <td>Before he was Sherlock’s rival, Moriarty fough...</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>[mystery, shounen, detectives, england, europe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title  \\\n",
       "0               Salad Days (Tang LiuZang) - Part 2   \n",
       "1                          The Master of Diabolism   \n",
       "2  JoJo's Bizarre Adventure Part 7: Steel Ball Run   \n",
       "3                              A Sign of Affection   \n",
       "4                             Moriarty the Patriot   \n",
       "\n",
       "                                         description  rating    year  \\\n",
       "0    The second season of Salad Days (Tang LiuZang).     4.7  2021.0   \n",
       "1  As the grandmaster who founded the Demonic Sec...     4.7  2017.0   \n",
       "2  Set in 1890, Steel Ball Run spotlights Gyro Ze...     4.7  2004.0   \n",
       "3  Yuki is a typical college student, whose world...     4.7  2019.0   \n",
       "4  Before he was Sherlock’s rival, Moriarty fough...     4.7  2016.0   \n",
       "\n",
       "                                                tags  \n",
       "0  [bl, manhua, romance, shounen-ai, sports, webt...  \n",
       "1  [action, adventure, bl, comedy, manhua, myster...  \n",
       "2  [action, adventure, horror, mystery, seinen, 1...  \n",
       "3         [romance, shoujo, sliceoflife, disability]  \n",
       "4  [mystery, shounen, detectives, england, europe...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "remove = ['cover']\n",
    "df = df.drop(columns=remove)\n",
    "df = df.drop_duplicates(subset='title')\n",
    "\n",
    "df['tags'] = df['tags'].apply(literal_eval)\n",
    "df['tags'] = df['tags'].apply(get_list)\n",
    "df['tags'] = df['tags'].apply(clean_data)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.2: Description Factors\n",
    "Starting with the first factor, let's use TFIDF which can deal well with importance of each word in a summary since it is equiped for that. Because we're looking at details that describe a plot line, it's better to use this method to calculate the values of what the descriptions can compare to. Similar to step 1, we just create a matrix of the words as values and do the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "df['description'] = df['description'].fillna('')\n",
    "description_matrix = tfidf.fit_transform(df['description']).astype(np.float32)\n",
    "\n",
    "description_score = linear_kernel(description_matrix, description_matrix).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.3: Rating Factors\n",
    "Looking at ratings, we can quickly mention that ratings don't mean everything but it's still a very solid guideline when looking for new things to consume. You would always want to look for better ratings. We can just easily do that with some normalizing of the rating number and let's add that number as a column to save the values. BUT normalizing may leave out the fact that lower ratings are much more not sought out so we need to penalize low ratings and benefit higher ratings in recommending according to rating.\n",
    "\n",
    "If the recommendation really fits your taste, a lower rating should not matter. But when there are a lot of options, we definitely want recommendations with higher ratings to be recommended. I took it upon myself to come up with something I would like to see and drew some example equations on Desmos. Since I wanted higher ratings from 4-5 to be recommended but lower ratings to be around the same (so that, in my logic, when they compare to each other, the difference is not as large). My equation is\n",
    "$$\\frac{e^{1.34R_{old}}}{811} = R_{new}$$\n",
    "\n",
    "Lil' awkward but I'm learning and trying things out so for now this is what I've got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponent_ratings(x):\n",
    "    return (np.exp(1.34 * x)) / 811\n",
    "\n",
    "df['rating_score'] = df['rating'].apply(exponent_ratings).astype(np.float32).fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.4: Year Factors\n",
    "Well, what a bummer. Honestly did my research but I couldn't find any efficient way to calculate year. Most other people working on recommender systems really focus on tags, keywords, casts, ratings, reviews, and descriptions but nothing really stood out to me to calculate year difference which I think could really help with defining some recommendations. Some people don't like art styles from the 90s while others prefer the format of more recent styles and I just couldn't calculate that.\n",
    "\n",
    "My plan was plain simple. Create a function to calculate the year difference and produce a value that encourages smaller year differences. The score for year would be calculated that way. But because the nature of my plan was different from what I've learned from tutorials on other features, I couldn't carry over similar transformations for the matrix/array to produce something fast. After multiple attempts from 2 minute runs to 30 minute runs, the code always managed to crash while trying to formulate numbers. It was too hard to fill in every value of the comparison map in 70k entries. Maybe a different database would be easier to deal with. But for now, I will just move on since, after all, this is just experimenting and practicing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_year(x):\n",
    "    n = len(x)\n",
    "    matrix = np.zeros((n, n), dtype=np.float32)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            matrix[i, j] = 1 / (1 + abs(x[i] - x[j]))\n",
    "    return matrix\n",
    "\n",
    "year_score = calculate_year(df['year'].values.astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.5: Tags Factors\n",
    "To be completely honest, I had a really hard time picking between the two methods of calculating the similarity score for tags. In the end, I chose CountVectorizer since I wanted the tags correlation to be more straightforward rather than weighing of each words in each tag since the description does more of that. In hopes that description can cover for what tags cannot, I decided to stick with CountVectorizer. This section is essentially the copy of that code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "df['soup'] = df.apply(create_soup, axis=1)\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(df['soup']).astype(np.float32)\n",
    "\n",
    "tags_score = cosine_similarity(count_matrix, count_matrix).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2.6: Combine Factors\n",
    "Excuse the extreme conversion of all the values near end, there was an issue with my device being unable to run the creation of final_score so I needed to shrink the types. The values I choose to be the weights are quite arbitrary as there is no perfect way I can find to see which values are the best. The process of approving the values is difficult since my thoughts on what should be recommended is very subjective, hence, I cannot say when it is a wrong recommendation or correct. After tinkering a bit, this is what I found to be the best attempt. Also very difficult to say because, on my device, it takes over an hour to run every length of this code hence difficult to redo and retest. If I had a better device, cloud computing, or optimized code, I would probably be able to test and measure all day and night long, but this is what I could come up with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_score = description_score.astype(np.float16)\n",
    "tags_score = tags_score.astype(np.float16)\n",
    "rating_score = df['rating_score'].values.astype(np.float16)\n",
    "year_score = year_score.astype(np.float16)\n",
    "final_score = (0.37 * description_score) +  (0.68 * tags_score) + (0.19 * df['rating_score'].values[np.newaxis, :]) + (0.09 * year_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_recs(titles, similarity, amt):\n",
    "    all_recommendations = []\n",
    "\n",
    "    for title in titles:\n",
    "        idx = indices[title]\n",
    "        scores = list(enumerate(similarity[idx]))\n",
    "        scores = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "        scores = scores[1:amt+1]  \n",
    "\n",
    "        recommended_indices = [i[0] for i in scores]\n",
    "        all_scores = [i[1] for i in scores]\n",
    "\n",
    "        recommended_titles = df['title'].iloc[recommended_indices].reset_index(drop=True)\n",
    "        recommendations = pd.DataFrame({'title': recommended_titles, 'scores': all_scores})\n",
    "\n",
    "        all_recommendations.append(recommendations)\n",
    "\n",
    "    combined_recommendations = pd.concat(all_recommendations).reset_index(drop=True)\n",
    "    sorted_recommendations = combined_recommendations.sort_values(by='scores', ascending=False).reset_index(drop=True)\n",
    "    return sorted_recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                title    scores\n",
      "0                      Who Made Me a Princess (Novel)  0.949432\n",
      "1                       Becoming the Villain’s Family  0.742264\n",
      "2                                    A Chance At Last  0.741970\n",
      "3                     Flirting with The Villain's Dad  0.737576\n",
      "4                      The Red Knight Seeks No Reward  0.733174\n",
      "5                    The Villainess Flips the Script!  0.733067\n",
      "6                                Miss Not-So Sidekick  0.727947\n",
      "7   The Story of a Low-Rank Soldier Becoming a Mon...  0.718693\n",
      "8                       Trump (Chae-Eun LEE) - Part 4  0.710357\n",
      "9                         Masters of Lightning Knives  0.701580\n",
      "10                              Tower of God - Part 3  0.698311\n",
      "11                                       Princess Shu  0.690508\n",
      "12                                      Kill the Hero  0.687932\n",
      "13                              The Marriage Business  0.686199\n",
      "14                                    Blood Strangers  0.685460\n",
      "15                            My Roommate is a Gumiho  0.683078\n",
      "16                                             Roxana  0.682441\n",
      "17                         Straight to the Red Carpet  0.680928\n",
      "18                   This Villainess Wants a Divorce!  0.677563\n",
      "19                       My Life as an Internet Novel  0.667694\n",
      "20                                  Magician - Part 3  0.661214\n",
      "21                                           Dracorun  0.657264\n",
      "22                      The Second Coming of Gluttony  0.647869\n",
      "23                      Trump (Chae-Eun LEE) - Part 3  0.642837\n"
     ]
    }
   ],
   "source": [
    "titles = ['Who Made Me a Princess', 'Lady Baby', 'Daughter of the Archmage']\n",
    "indices = pd.Series(df.index, index=df['title'])\n",
    "top_recs = get_top_recs(titles, final_score, 8)\n",
    "print(top_recs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
